{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "\n",
    "This notebook will review the procedure of developing a semantic segmentation (supervised) model to map land use categories \n",
    "and illegal gold mining activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Segmentation Architecture\n",
    "\n",
    "Semantic Segmentation is often simplified into the combination of an encoder and a decoder. An encoder in this case generates logic or feedback from the input data, and a decoder takes that feedback and translates it to output data in the same form as the input. For the purposes of this procedure I will utilize a U-Net Segmentation architecture.\n",
    "\n",
    "As expected, the first layers of this model makes up the encoder strategies. More accurately, it consists of consecutive convolutional layers, each followed by a ReLU and a max pooling operation to encode feature representations at multiple scales. This is similar to other architectures which handle feature extraction networks designed for classification.\n",
    "\n",
    "The following layers makes up the decoder which is tasked to `semantically` project the discriminative deatures learned by the encoder onto the original pixel space to render dense classification. The decoder in this case constists of deconvolution or `Conv2DTranspose()` and concatenation followed by regular convolution operations.\n",
    "\n",
    "Expectedly, following the decoder operations is the final classification layer, which computes the pixel-wise classification for each cell in the final feature map.\n",
    "\n",
    "## Activation Functions and Operations\n",
    "\n",
    "`ReLU` is an activation function that induces non-linearity by intaking the feature map from a convolutional operation and remapping it such that any positive value stays exactly the same while any negative values become zero, thus unable to pass to the following layer in a meaningful way after max pooling operations.\n",
    "\n",
    "`max pooling` is an operation utilized to summarize a feature map and only retain the important structure elements, thus foregoing the more granular detail that may not be significant to the modeling task. In other words, this operation helps to denoise the signal and assists with computational efficiency. It operates similar to a convolution in that a kernal with a stride is applied to the feature map where only the maximum value within each patch is reserved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview\n",
    "\n",
    "A great resource you can use to demonstrate and develop these kinds of models is the `Planet` NICFI Satellite Data Program. In full: Norway's International Climate and Forests Initiative Satellite Data Program. Through this resourcem users can now access high-resolution, analysis-ready mosaics of the world's tropics. It has been demonstrated that this can help reduce and reverse the loss of tropical forests, combat climate change, conserve biodiversity, and facilitate sustainable development for non commercial use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access and mosaic `Planet` NICFI Monthly Basemaps.\n",
    "\n",
    "Access was accomplished by creating an account with the `Planet` NICFI resource, and obtaining a API key for data access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os, glob, functools, fnmatch, requests, io, shutil, tarfile, json\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from itertools import product\n",
    "from configparser import ConfigParser\n",
    "import urllib.request\n",
    "\n",
    "# Data Vis Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "# Geospatial Tools\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n",
    "from folium import Map, GeoJson, Figure\n",
    "from shapely.geometry import box\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from radiant_mlhub import Dataset, client, get_session, Collection # for dataset access (Open library for Earth Observations Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = [\n",
    "    'ref_african_crops_kenya_01_labels'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
